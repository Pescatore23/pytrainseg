{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c0f1c0-6da4-42f2-9911-7e2331b23b3a",
   "metadata": {},
   "source": [
    "## Part 1: feature stack creation and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b73384-f747-4c14-bbec-611b9f4ded5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary packages for feature stack\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import filters, feature, io\n",
    "from skimage.morphology import disk,ball\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import sys\n",
    "import dask\n",
    "import dask.array\n",
    "# import cupy as cp\n",
    "# import cucim\n",
    "from itertools import combinations_with_replacement\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47631229-5b13-468c-8b5e-38392e04c261",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.1 feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f7248b-5c6d-4187-9257-3871f5c657e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions take chunked dask-array as input\n",
    "def nd_gaussian(da, sig = 0):\n",
    "    if np.abs(sig-0)<0.1:\n",
    "        G = np.array(da)\n",
    "        fullname = 'original'\n",
    "    else:\n",
    "        deptharray = np.ones(da.ndim)+4*sig\n",
    "        deptharray = tuple(np.min([deptharray, da.shape], axis=0))\n",
    "        G = da.map_overlap(filters.gaussian, depth=deptharray, boundary='nearest', sigma = sig).compute()\n",
    "        # G = da.map_overlap(filters.gaussian, depth=4*sig+1, boundary='none', sigma = sig).compute()\n",
    "        fullname = ''.join(['gaussian_',f'{sig:.1f}'])\n",
    "    return G, fullname\n",
    "\n",
    "#TODO create a class that makes the feature stacks\n",
    "def nd_gaussian_stack(da, sigmas):\n",
    "    fullnames = []\n",
    "    gstack = np.zeros(list(da.shape) + [len(sigmas)])\n",
    "    for sig,i in zip(sigmas, range(len(sigmas))):\n",
    "        gstack[...,i], name = nd_gaussian(da, sig)\n",
    "        fullnames.append(name)\n",
    "    return gstack, fullnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d6fbf3-01c4-4d7b-bbd0-8b6271249979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd_diff_of_gaussian(gstack, sigmas):\n",
    "#     #creates a stack of {size} (see below)\n",
    "    n = len(sigmas)\n",
    "    size = int(n*(n-1)/2)\n",
    "    dstack = np.zeros(list(da.shape) + [size])\n",
    "    fullnames = []\n",
    "    cc = 0\n",
    "    for i in range(1,n):\n",
    "        for j in range(i):\n",
    "            dstack[...,cc] = gstack[...,i] - gstack[...,j]\n",
    "            name = ''.join(['diff_of_gauss_',f'{sigmas[i]:.1f}','_',f'{sigmas[j]:.1f}'])\n",
    "            fullnames.append(name)\n",
    "            cc = cc + 1\n",
    "    return dstack, fullnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02de82f3-ba96-4b85-a85a-b81a7f413a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball_4d(sig):\n",
    "    bnd = np.zeros((sig*2+1,sig*2+1,sig*2+1,sig*2+1), dtype = bool)\n",
    "    bnd[sig,sig,sig,sig] = True\n",
    "    ecd = ndimage.distance_transform_edt(~bnd)\n",
    "    bnd = (ecd<sig+0.01).astype(int)\n",
    "    return bnd\n",
    "\n",
    "def nd_rank_like_filter(da, sigma, option):\n",
    "    \"\"\"\n",
    "     input\n",
    "     da - chunked das array up to 4D\n",
    "     sigma - kernel size, scalar\n",
    "     option, str ('minimum', 'maximum', 'median')\n",
    "    \"\"\"\n",
    "    if da.ndim == 2:\n",
    "        fp = disk(sigma)\n",
    "    if da.ndim == 3:\n",
    "        fp = ball(sigma)\n",
    "    if da.ndim == 4:\n",
    "        fp = ball_4d(sigma)\n",
    "        \n",
    "    if option == 'minimum':\n",
    "        fun = ndimage.minimum_filter\n",
    "    elif option == 'maximum':\n",
    "        fun = ndimage.maximum_filter\n",
    "    elif option == 'median':\n",
    "        fun = ndimage.median_filter\n",
    "    else:\n",
    "        print(option+' not available')\n",
    "    deptharray = np.ones(da.ndim)+sigma\n",
    "    deptharray = tuple(np.min([deptharray, da.shape], axis=0))\n",
    "    M = da.map_overlap(fun, depth=deptharray, footprint=fp).compute()\n",
    "    # M = da.map_overlap(fun, depth=sigma+1, footprint=fp).compute()\n",
    "    fullname = ''.join([option,'_',f'{sigma:.1f}'])\n",
    "    return M, fullname\n",
    "\n",
    "def nd_rank_like_stack(da, sigmas, option):\n",
    "    fullnames = []\n",
    "    mstack = np.zeros(list(da.shape) + [len(sigmas)-1])\n",
    "    for sig,i in zip(sigmas[1:], range(len(sigmas)-1)):\n",
    "        mstack[...,i], name = nd_rank_like_filter(da, sig, option)\n",
    "        fullnames.append(name)\n",
    "    return mstack, fullnames   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401c4f79-98a5-435a-a255-22bae402418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd_Hessian_matrix(G):\n",
    "    \"\"\"\n",
    "    copied from skimage.feature.hessian_matrix\n",
    "    just directly using Gaussian fitered arrays and dask\n",
    "    \"\"\"\n",
    "    \n",
    "    daG = dask.array.from_array(G)\n",
    "    gradients = dask.array.gradient(daG)\n",
    "    axes = range(G.ndim)\n",
    "    H_elems = [dask.array.gradient(gradients[ax0], axis=ax1).compute() for ax0, ax1 in combinations_with_replacement(axes, 2)]\n",
    "    elems = [(ax0,ax1) for ax0, ax1 in combinations_with_replacement(axes, 2)]\n",
    "    return H_elems, elems\n",
    "\n",
    "def nd_Hessian_stack(G, sigma):\n",
    "    H_elems, elems = nd_Hessian_matrix(G)\n",
    "    hstack = np.zeros(list(G.shape)+[len(elems)])\n",
    "    \n",
    "    #TODO: this is slow, find some better numpy function\n",
    "    for i in range(len(elems)):\n",
    "        hstack[...,i] = H_elems[i]\n",
    "    \n",
    "    # print('got Hessian matrices, now doing the eigs')\n",
    "    # eigs = feature.hessian_matrix_eigvals(H_elems) \n",
    " # for now ignore the eigenvalues (too computationally expensive and H_elems already contains the image curvature  \n",
    "\n",
    "    fullnames = []\n",
    "    for i,j in elems:\n",
    "        fullname = ''.join(['hessian_',str(i),str(j),'_',f'{sigma:.1f}'])\n",
    "        fullnames.append(fullname) \n",
    "        \n",
    "    return hstack, fullnames\n",
    "\n",
    "def nd_Hessian_stacks(gstack, sigmas):\n",
    "    flag = True\n",
    "    fullnames = []\n",
    "    for (i, sigma) in zip(range(gstack.shape[-1]), sigmas):\n",
    "        a, b = nd_Hessian_stack(gstack[...,i], sigma)\n",
    "        asize = a.shape[-1]\n",
    "        if flag:\n",
    "            flag = False\n",
    "            hstacks = np.zeros(list(gstack[...,-1].shape)+[len(sigmas)*asize])\n",
    "        hstacks[...,i*asize:i*asize+asize] = a\n",
    "        fullnames = fullnames + b\n",
    "    return hstacks, fullnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65898c62-240b-47ed-a137-5b93f7adb84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nd_feature_Stack(da, sigmas, feat_select):\n",
    "#     TODO: make more elegant\n",
    "    \n",
    "    fstack = []\n",
    "    featnames = []\n",
    "    \n",
    "    print('apply Gaussian filters anyway')\n",
    "    gstack, gnames = nd_gaussian_stack(da, sigmas)\n",
    "    \n",
    "    if feat_select['Gaussian']:\n",
    "        featnames = featnames + gnames\n",
    "        fstack.append(gstack)\n",
    "        \n",
    "    if feat_select['Hessian']:\n",
    "        print('get Hessian matrices')\n",
    "        hstack, hnames = nd_Hessian_stacks(gstack, sigmas)\n",
    "        featnames = featnames + hnames \n",
    "        fstack.append(hstack)\n",
    "        \n",
    "    if feat_select['Diff of Gaussians']:\n",
    "        print('get differences of Gaussians')\n",
    "        dstack, dnames = nd_diff_of_gaussian(gstack, sigmas)\n",
    "        featnames = featnames + dnames\n",
    "        fstack.append(dstack)\n",
    "        \n",
    "    if feat_select['maximum']:\n",
    "        print('apply maximum filters')\n",
    "        maxstack, maxnames = nd_rank_like_stack(da, sigmas, option='maximum')\n",
    "        featnames = featnames + maxnames\n",
    "        fstack.append(maxstack)\n",
    "        \n",
    "    if feat_select['median']:\n",
    "        print('apply median filters')\n",
    "        medstack, mednames = nd_rank_like_stack(da, sigmas, option='median')\n",
    "        featnames = featnames + mednames\n",
    "        fstack.append(medstack)\n",
    "        \n",
    "    if feat_select['minimum']:\n",
    "        print('apply minimum filters')\n",
    "        minstack, minnames = nd_rank_like_stack(da, sigmas, option='minimum')\n",
    "        featnames = featnames + minnames\n",
    "        fstack.append(minstack)\n",
    "        \n",
    "    return np.concatenate(fstack, axis=-1), featnames\n",
    "\n",
    "def feat_stack_to_nc(fstack, featnames, path = None, name = 'test'):\n",
    "    #TODO: include metadata and make general, now only 4D possible\n",
    "    data = xr.Dataset({'feature_stack': (['x','y','z','time', 'feature'], fstack)},\n",
    "                       coords = {'x': np.arange(fstack.shape[0]),\n",
    "                                 'y': np.arange(fstack.shape[1]),\n",
    "                                 'z': np.arange(fstack.shape[2]),\n",
    "                                 'time': np.arange(fstack.shape[3]),\n",
    "                                 'feature': featnames}\n",
    "                      # attrs = feat_select)\n",
    "                     )\n",
    "    data.attrs['name'] = name\n",
    "    if path is not None:\n",
    "        data.to_netcdf(path)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b206687-56a8-45d2-8b1c-7cf3366cdaf8",
   "metadata": {},
   "source": [
    "### 1.2 load 4D dataset into dask-array TODO: employ datastreaming for datasets that are too large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88a88d1-9ac8-4621-849e-786d13d05a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "da = None\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dca7898a-f67b-4cb6-b802-de400a7e128b",
   "metadata": {},
   "source": [
    "### provisoric manual loading of Jerermy's data\n",
    "step1 = io.imread('/home/fische_r/NAS/testing/Jeremy_data/cropped/step_01.tif')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "876602a4-2bbd-47e5-8fa5-e826abfda0eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "step1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40340d95-3045-45e8-a64f-7d9bc80a9c4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "J_4D_data = np.zeros(list(step1.shape)+[8])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49c58cf1-d6a7-4d55-b500-82659c2a949c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "folder = '/home/fische_r/NAS/testing/Jeremy_data/cropped'\n",
    "files = os.listdir(folder)\n",
    "files.sort()\n",
    "for i in range(len(files)):\n",
    "    print(files[i])\n",
    "    J_4D_data[...,i] = io.imread(os.path.join(folder, files[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd9de41b-250b-4839-b748-6ca6f4f5ec5e",
   "metadata": {},
   "source": [
    "plt.imshow(J_4D_data[500,:,:,4])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b6553b7-5001-4541-8c60-7b07541e2f49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "step1=None\n",
    "J_4D_data = J_4D_data[500:700,...]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8afa45ef-9a4a-4da6-85dc-a6d227aab0be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "data = xr.Dataset({'tomo': (['x','y','z','t'], J_4D_data)},\n",
    "                  coords = {'x': np.arange(J_4D_data.shape[0]),\n",
    "                            'y': np.arange(J_4D_data.shape[1]),\n",
    "                            'z': np.arange(J_4D_data.shape[2]),\n",
    "                            't': np.arange(J_4D_data.shape[3])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5586ac1f-9516-4344-b1c9-e01a0b69a70b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.to_netcdf(os.path.join(folder, 'tomodata.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1e5c3a-5f2a-4b32-97d8-32e752c9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load some yarn data\n",
    "rawdata = xr.load_dataset('/home/fische_r/NAS/testing/testing/Jeremy_tomo/tomodata.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa0dbc9e-6adc-4044-bc90-36b91231382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "da = dask.array.from_array(rawdata['tomo'].data, chunks= '10 MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87d88879-1463-48e9-8fc9-f98b91d936cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 110.93 MiB </td>\n",
       "                        <td> 7.62 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (200, 39, 233, 8) </td>\n",
       "                        <td> (50, 39, 64, 8) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 16 Tasks </td>\n",
       "                        <td> 16 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float64 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"452\" height=\"194\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"103\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"25\" x2=\"103\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"25\" y1=\"0\" x2=\"25\" y2=\"25\" />\n",
       "  <line x1=\"51\" y1=\"0\" x2=\"51\" y2=\"25\" />\n",
       "  <line x1=\"77\" y1=\"0\" x2=\"77\" y2=\"25\" />\n",
       "  <line x1=\"103\" y1=\"0\" x2=\"103\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 103.00429184549355,0.0 103.00429184549355,25.412616514582485 0.0,25.412616514582485\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"51.502146\" y=\"45.412617\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >200</text>\n",
       "  <text x=\"123.004292\" y=\"12.706308\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(0,123.004292,12.706308)\">1</text>\n",
       "\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"173\" y1=\"0\" x2=\"197\" y2=\"24\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"173\" y1=\"32\" x2=\"197\" y2=\"57\" />\n",
       "  <line x1=\"173\" y1=\"65\" x2=\"197\" y2=\"90\" />\n",
       "  <line x1=\"173\" y1=\"98\" x2=\"197\" y2=\"123\" />\n",
       "  <line x1=\"173\" y1=\"120\" x2=\"197\" y2=\"144\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"173\" y1=\"0\" x2=\"173\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"197\" y1=\"24\" x2=\"197\" y2=\"144\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"173.0,0.0 197.24915781783616,24.249157817836156 197.24915781783616,144.24915781783616 173.0,120.0\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"173\" y1=\"0\" x2=\"205\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"197\" y1=\"24\" x2=\"229\" y2=\"24\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"173\" y1=\"0\" x2=\"197\" y2=\"24\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"205\" y1=\"0\" x2=\"229\" y2=\"24\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"173.0,0.0 205.20356383232797,0.0 229.45272165016414,24.249157817836156 197.24915781783616,24.249157817836156\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"197\" y1=\"24\" x2=\"229\" y2=\"24\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"197\" y1=\"57\" x2=\"229\" y2=\"57\" />\n",
       "  <line x1=\"197\" y1=\"90\" x2=\"229\" y2=\"90\" />\n",
       "  <line x1=\"197\" y1=\"123\" x2=\"229\" y2=\"123\" />\n",
       "  <line x1=\"197\" y1=\"144\" x2=\"229\" y2=\"144\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"197\" y1=\"24\" x2=\"197\" y2=\"144\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"229\" y1=\"24\" x2=\"229\" y2=\"144\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"197.24915781783616,24.249157817836156 229.45272165016414,24.249157817836156 229.45272165016414,144.24915781783616 197.24915781783616,144.24915781783616\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"213.350940\" y=\"164.249158\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >8</text>\n",
       "  <text x=\"249.452722\" y=\"84.249158\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,249.452722,84.249158)\">233</text>\n",
       "  <text x=\"175.124579\" y=\"152.124579\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,175.124579,152.124579)\">39</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<array, shape=(200, 39, 233, 8), dtype=float64, chunksize=(50, 39, 64, 8), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815f4651-49a7-4669-8cc7-b3382f2e157a",
   "metadata": {},
   "source": [
    "### 1.3 feature settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ccaf6d-8921-4e94-ab6c-f0ff46432443",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = [0, 2,4, 8]  #hard-coded for now, sobel and hessian require that first sigma is 0, diff, gaussian(sig=0) = 0\n",
    "\n",
    "# default feature choice\n",
    "feat_select = {'Gaussian': True, \n",
    "               # 'Sobel': True,\n",
    "               'Hessian': True,\n",
    "               'Diff of Gaussians': True,\n",
    "               'maximum': True,\n",
    "               'minimum': True,\n",
    "               'median': True\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a00402e-a7bc-4eae-ad31-04950094df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd546b0-b13c-4403-a3c1-7a9f0cfb509a",
   "metadata": {},
   "source": [
    "### 1.4 Create and store feature stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdb1c7b8-85bb-4707-b9ae-15716a621558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output path\n",
    "outpath = '/home/fische_r/NAS/testing/testing/Jeremy_tomo/feat_stack.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1f364-d2c8-4fba-accf-931372c90622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apply Gaussian filters anyway\n",
      "get Hessian matrices\n",
      "get differences of Gaussians\n",
      "apply maximum filters\n"
     ]
    }
   ],
   "source": [
    "#this may take a while depending on the size and system\n",
    "# may even crash because out of memory\n",
    "\n",
    "fstack, featnames = nd_feature_Stack(da, sigmas, feat_select)\n",
    "data = feat_stack_to_nc(fstack, featnames, outpath, feat_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118e8f3-4f2f-41ff-8727-e3ac67d1848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fstack = None\n",
    "data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ac0c2-2822-4426-a4a1-1fdb3260dd63",
   "metadata": {},
   "source": [
    "## Part 2: Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06898513-bb61-4052-b95f-3c82a7f5c217",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#the classifier\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#stuff for painting on the image\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# necessary packages\n",
    "\n",
    "#reload after kernel reset\n",
    "import xarray as xr\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#the classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#stuff for painting on the image\n",
    "from ipywidgets import Image\n",
    "from ipywidgets import ColorPicker, IntSlider, link, AppLayout, HBox\n",
    "from ipycanvas import  hold_canvas,  MultiCanvas #RoughCanvas,Canvas,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330271b-005b-410b-9f50-c7572ce71f75",
   "metadata": {},
   "source": [
    "### 2.1 open (not load) feature stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e8e87-adcb-4351-ab29-1a701ecc5dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "featpath = '/somewhere'\n",
    "traininpath = '/somewhere/else'\n",
    "feat_data = xr.open_dataset(featpath)\n",
    "feat_names = feat_data['feature'].data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f055df-ca38-49d4-af3c-eb9048643051",
   "metadata": {},
   "source": [
    "### 2.2 training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83050a3a-24c4-4aed-83a2-3ec1cdeffc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_training_data(im, truth, feat_stack):\n",
    "    #pixelwise training data\n",
    "    phase1 = truth==1\n",
    "    phase2 = truth==2\n",
    "    phase3 = truth==4   \n",
    "    X1 = feat_stack[phase1]\n",
    "    y1 = np.zeros(X1.shape[0])\n",
    "    X2 = feat_stack[phase2]\n",
    "    y2 = np.ones(X2.shape[0])\n",
    "    X3 = feat_stack[phase3]\n",
    "    y3 = 2*np.ones(X3.shape[0])\n",
    "\n",
    "    y = np.concatenate([y1,y2,y3])\n",
    "    X = np.concatenate([X1,X2,X3])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45efa62a-177f-4a07-a772-1cfb2c788347",
   "metadata": {},
   "outputs": [],
   "source": [
    " def classify(X,y,im, feat_stack):\n",
    "    # TODO: allow choice and manipulation of ML method\n",
    "    clf =  RandomForestClassifier(n_estimators = 300, n_jobs=-1, random_state = 42, max_features=None) \n",
    "    clf.fit(X, y)\n",
    "    num_feat = feat_stack.shape[2]\n",
    "    ypred = clf.predict(feat_stack.reshape(-1,num_feat))\n",
    "    result = ypred.reshape(im.shape).astype(np.uint8)\n",
    "    return result, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661cd3a-04ef-4d5c-9d4e-a9059dce77b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(im, truth, feat_stack, training_dict, slice_name):\n",
    "    slices = list(training_dict.keys())\n",
    "    if slice_name in slices: \n",
    "        slices.remove(slice_name)\n",
    "    if len(slices)>0:\n",
    "        flag = True\n",
    "        Xall = training_dict[slices[0]][0]\n",
    "        yall = training_dict[slices[0]][1]\n",
    "        for i in range(1,len(slices)):\n",
    "            Xall = np.concatenate([Xall, training_dict[slices[i]][0]])\n",
    "            yall = np.concatenate([yall, training_dict[slices[i]][1]])\n",
    "            \n",
    "    X,y = extract_training_data(im, truth, feat_stack)\n",
    "    \n",
    "    print('training and classifying')\n",
    "    \n",
    "    if flag:\n",
    "        Xt = np.concatenate([Xall,X])\n",
    "        yt = np.concatenate([yall,y])\n",
    "        Xall = None\n",
    "        yall = None\n",
    "    else:\n",
    "        Xt = X\n",
    "        yt = y  \n",
    "    result, clf = classify(Xt, yt, im, feat_stack)\n",
    "    \n",
    "    # store training data of current slice in dict\n",
    "    training_dict[slice_name] = (X,y)\n",
    "    return result, clf, training_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f521743-af65-49e7-979b-68be9f667ef4",
   "metadata": {},
   "source": [
    "### 2.3 select 2D-slice and create a training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbfeb471-f3d7-408d-8be5-2ffe60a2a7aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You could try  z = 7  and  x = 50\n"
     ]
    }
   ],
   "source": [
    "# randomly suggest slice for training\n",
    "# TODO: take coordinates from feat_data\n",
    "dimensions = ['x','y','z','t']\n",
    "\n",
    "test_dims = np.random.choice(dimensions, 2, replace=False)\n",
    "# p1 = np.random.choice(range(len(feat_data[test_dims[0]])))\n",
    "# p2 = np.random.choice(range(len(feat_data[test_dims[1]])))\n",
    "\n",
    "print('You could try ',test_dims[0],'=',p1,' and ',test_dims[1],'=',p2)\n",
    "# ts = np.random.choice(range(num_ts))+1\n",
    "# print('try time step ',ts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7cf1b7-2bc0-426e-b1ed-cb6bc86b909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select 2D slice orthogonal to these two axes\n",
    "#replace dimensions in .sel accordingly, d1c and d2c are needed for filename\n",
    "#TODO: make more elegant\n",
    "d1c = 'z'\n",
    "d2c = 't'\n",
    "p1c = 500\n",
    "p2c = 50\n",
    "\n",
    "im = feat_data['feature_stack'].sel(z = p1c, t = pc2, feature='orignal').data\n",
    "im8 = np.uint8(im)\n",
    "feat_stack = feat_data['feature_stack'].sel(z = p1c, t = pc2).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fabe8-542b-4586-b0e7-19d62dc01004",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdry = feat_data['feature_stack'].sel(y = p1c, time = 0, feature='original').data\n",
    "diff = im-imdry\n",
    "diff = diff/diff.max()*255\n",
    "diff[diff<0]=0\n",
    "diff[diff>255] = 255\n",
    "\n",
    "imdry = imdry-imdry.min()\n",
    "imdry = imdry/imdry.max()*255\n",
    "imdry = imdry-50\n",
    "imdry[imdry<0]=0\n",
    "imdry=imdry*255/150\n",
    "imdry[imdry>255] = 255\n",
    "\n",
    "im8 = im-im.min()\n",
    "im8 = im8/im8.max()*255\n",
    "im8 = im8-50\n",
    "im8[im8<0]=0\n",
    "im8=im8*255/150\n",
    "im8[im8>255] = 255\n",
    "# im8old = im8.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6932a-ce94-41ef-a06e-261962a1f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name = ''.join([str(d1c),str(p1c),str(d2c),str(p2c)])\n",
    "truthpath = os.path.join(trainingpath, ''.join(['label_image_',slice_name,'.tif']))\n",
    "\n",
    "resultim = np.zeros(im.shape, dtype=np.uint8)\n",
    "if os.path.exists(truthpath):\n",
    "    truth = io.imread(truthpath)\n",
    "    print('existing label set loaded')\n",
    "else:\n",
    "    truth = resultim.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff055922-4510-442b-bab6-f7ae5f1b339b",
   "metadata": {},
   "source": [
    "### 2.4 training interface\n",
    "currently only 3 phases possible <br />\n",
    "manually specify #ff000 (phase 1) #00ff00 (phase 2) or #0000ff (phase 3) as color and paint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29033e9d-6678-43d7-8048-33184cd33d74",
   "metadata": {},
   "source": [
    "#### 2.4.1 label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a36de-acc2-459b-b5f4-41dee54120a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = im8.shape[1]\n",
    "height = im8.shape[0]\n",
    "\n",
    "Mcanvas = MultiCanvas(4, width=width, height=height)\n",
    "background = Mcanvas[0]\n",
    "resultdisplay = Mcanvas[2]\n",
    "truthdisplay = Mcanvas[1]\n",
    "canvas = Mcanvas[3]\n",
    "canvas.sync_image_data = True\n",
    "\n",
    "drawing = False\n",
    "position = None\n",
    "shape = []\n",
    "\n",
    "def on_mouse_down(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    drawing = True\n",
    "    position = (x, y)\n",
    "    shape = [position]\n",
    "\n",
    "def on_mouse_move(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    if not drawing:\n",
    "        return\n",
    "\n",
    "    with hold_canvas():\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "\n",
    "        position = (x, y)\n",
    "\n",
    "    shape.append(position)\n",
    "\n",
    "def on_mouse_up(x, y):\n",
    "    global drawing\n",
    "    global position\n",
    "    global shape\n",
    "\n",
    "    drawing = False\n",
    "\n",
    "    with hold_canvas():\n",
    "        canvas.stroke_line(position[0], position[1], x, y)\n",
    "        canvas.fill_polygon(shape)\n",
    "\n",
    "    shape = []\n",
    "\n",
    "image_data = np.stack((im8, im8, im8), axis=2)\n",
    "background.put_image_data(image_data, 0, 0)\n",
    "\n",
    "resultdisplay.global_alpha = 0.15\n",
    "if np.any(resultim>0):\n",
    "    result_data = np.stack((255*(resultim==0), 255*(resultim==1), 255*(resultim==2)), axis=2)\n",
    "else:\n",
    "    result_data = np.stack((0*resultim, 0*resultim, 0*resultim), axis=2)\n",
    "resultdisplay.put_image_data(result_data, 0, 0)\n",
    "\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "\n",
    "# canvas.stroke_style = \"#749cb8\"\n",
    "# canvas.global_alpha = 0.75\n",
    "\n",
    "picker = ColorPicker(description=\"Color:\", value=\"#ff0000\")\n",
    "slidealpha = IntSlider(description=\"Result overlay\", value=0.15)\n",
    "\n",
    "link((picker, \"value\"), (canvas, \"stroke_style\"))\n",
    "link((picker, \"value\"), (canvas, \"fill_style\"))\n",
    "# link((slidealpha, \"value\"), (resultdisplay, \"global_alpha\"))\n",
    "\n",
    "HBox((Mcanvas, picker, slidealpha))\n",
    "#print('paint image with #ff0000 for air, #00ff00 for water and #0000ff for fiber')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5641b94f-b193-463a-a050-41dec93032bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff[diff<0] = 0\n",
    "fig, axes = plt.subplots(1,5, figsize=(24,10))\n",
    "axes[0].imshow(resultim)\n",
    "axes[1].imshow(im8, 'gray')\n",
    "axes[2].imshow(diff)\n",
    "# axes[3].imshow(im8old, 'gray')\n",
    "axes[3].imshow(imdry, 'gray')\n",
    "axes[4].imshow(truth)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bc696-805d-4960-ab46-7ef830fc0577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create truth image from image, save to file\n",
    "label_set = canvas.get_image_data()\n",
    "\n",
    "truth[label_set[:,:,0]>0] = 1\n",
    "truth[label_set[:,:,1]>0] = 2\n",
    "truth[label_set[:,:,2]>0] = 4\n",
    "\n",
    "imageio.imsave(truthpath, truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ee2a2-ab53-4639-8016-fd804c779e3d",
   "metadata": {},
   "source": [
    "#### 2.4.2 actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c9694-7792-420c-945e-19004a8dc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultim, clf, training_dict = training_function(im, truth, feat_stack, training_dict, slice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a9253-88ac-4b7b-a891-6f14cb245b3d",
   "metadata": {},
   "source": [
    "#### 2.4.3 iterative training: go back to 2.4.1 until good segmentation or try different slice at 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89646a07-dd33-4159-931e-220a8c1126d6",
   "metadata": {},
   "source": [
    "#### 2.4.4 plot classifier properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43bda24-a965-40dd-bf6d-6c35216541e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize=(16,9))\n",
    "plt.stem(feat_names,clf.feature_importances_,'x')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95286274-f5c7-475a-8bc4-f7242cf2be51",
   "metadata": {},
   "source": [
    "## 3 apply classifier to full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "333187e2-e21c-49be-9770-95d872ab0eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf4466-d54e-40b7-a05c-5a7d4bdbdbdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
